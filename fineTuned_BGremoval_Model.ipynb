{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2byHl9Xzyc9",
        "outputId": "3f8b86dd-b4e4-4835-ceaa-a3de4a20188b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets accelerate torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m37KMnCV1OaY",
        "outputId": "9a244ea8-0fd0-4a26-9750-b54eaf9cbebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `fine tuning` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `fine tuning`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQbYF6Hwf4hD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForImageSegmentation\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from huggingface_hub import create_repo\n",
        "from huggingface_hub import HfApi, upload_folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh3ZlHecVN3u",
        "outputId": "997df141-eba8-4351-8355-e99eb4bf4b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['original_image', 'sign_mask', 'robot_depth', 'transparent_image',\n",
            "       'mask_image'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_parquet(\"hf://datasets/svjack/ZHONGLI_Holding_A_Sign_Images_MASK_DEPTH_RMBG_1024x1024/data/train-00000-of-00001.parquet\")\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-sOYIWp9aJH"
      },
      "outputs": [],
      "source": [
        "def decode_image(entry):\n",
        "    if isinstance(entry, dict):\n",
        "        entry = entry.get(\"bytes\", b\"\")\n",
        "    if not isinstance(entry, (bytes, bytearray)):\n",
        "        raise ValueError(\"Image data is not raw bytes\")\n",
        "    return Image.open(BytesIO(entry)).convert(\"RGB\")\n",
        "\n",
        "def decode_mask(entry):\n",
        "    if isinstance(entry, dict):\n",
        "        entry = entry.get(\"bytes\", b\"\")\n",
        "    if not isinstance(entry, (bytes, bytearray)):\n",
        "        raise ValueError(\"Mask data is not raw bytes\")\n",
        "    return Image.open(BytesIO(entry)).convert(\"L\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCfhd844gAfO"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89RkpRg6gDBb"
      },
      "outputs": [],
      "source": [
        "class RMBGDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.image_transform = transforms.Compose([\n",
        "            transforms.Resize((1024, 1024)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        self.mask_transform = transforms.Compose([\n",
        "            transforms.Resize((1024, 1024)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = decode_image(self.df.iloc[idx][\"original_image\"])\n",
        "        mask = decode_mask(self.df.iloc[idx][\"mask_image\"])\n",
        "        return {\n",
        "            \"pixel_values\": self.image_transform(image),\n",
        "            \"mask\": self.mask_transform(mask),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pv69tGvMV-cP"
      },
      "outputs": [],
      "source": [
        "class LoRAConv2d(nn.Module):\n",
        "    def __init__(self, conv: nn.Conv2d, r=4, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.conv = conv\n",
        "        self.r = r\n",
        "        self.alpha = alpha\n",
        "        self.scaling = alpha / r\n",
        "\n",
        "        self.lora_A = nn.Conv2d(conv.in_channels, r, kernel_size=1, bias=False)\n",
        "        self.lora_B = nn.Conv2d(r, conv.out_channels, kernel_size=1, bias=False)\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.lora_A.weight, a=5**0.5)\n",
        "        nn.init.zeros_(self.lora_B.weight)\n",
        "\n",
        "        for param in self.conv.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        a_out = self.lora_A(x)\n",
        "        b_out = self.lora_B(a_out)\n",
        "\n",
        "        conv_out = self.conv(x)\n",
        "\n",
        "        # Resize b_out to match conv_out spatial shape\n",
        "        if b_out.shape[-2:] != conv_out.shape[-2:]:\n",
        "            b_out = nn.functional.interpolate(\n",
        "                b_out,\n",
        "                size=conv_out.shape[-2:],\n",
        "                mode=\"bilinear\",\n",
        "                align_corners=False\n",
        "            )\n",
        "\n",
        "        out = conv_out + b_out * self.scaling\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXlFPO_JQJGD",
        "outputId": "f2985442-55f9-4a08-8d4b-1cef394c32f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BriaRMBG(\n",
              "  (conv_in): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (pool_in): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage1): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage2): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage3): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage4): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool45): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage5): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool56): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage6): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage5d): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage4d): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage3d): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage2d): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1d): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (side1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (side2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (side3): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (side4): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (side5): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (side6): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\", trust_remote_code=True)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO0znsPBgW0K",
        "outputId": "7ede97d9-7f9d-4ed9-a31c-ece400b153de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers to wrap: [('conv_in', Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))), ('stage1.rebnconvin.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv1.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv2.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv3.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv4.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv5.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv6.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv7.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage1.rebnconv6d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv5d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv4d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv3d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv2d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1.rebnconv1d.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconvin.conv_s1', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv1.conv_s1', Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv2.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv3.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv4.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv5.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv6.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage2.rebnconv5d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv4d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv3d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv2d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2.rebnconv1d.conv_s1', Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconvin.conv_s1', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv1.conv_s1', Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv2.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv3.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv4.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv5.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage3.rebnconv4d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv3d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv2d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3.rebnconv1d.conv_s1', Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconvin.conv_s1', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv1.conv_s1', Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv2.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv3.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv4.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage4.rebnconv3d.conv_s1', Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv2d.conv_s1', Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4.rebnconv1d.conv_s1', Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5.rebnconvin.conv_s1', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5.rebnconv1.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5.rebnconv2.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage5.rebnconv3.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage5.rebnconv4.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))), ('stage5.rebnconv3d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage5.rebnconv2d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage5.rebnconv1d.conv_s1', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage6.rebnconvin.conv_s1', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage6.rebnconv1.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage6.rebnconv2.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage6.rebnconv3.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage6.rebnconv4.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))), ('stage6.rebnconv3d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage6.rebnconv2d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage6.rebnconv1d.conv_s1', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5d.rebnconvin.conv_s1', Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5d.rebnconv1.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage5d.rebnconv2.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage5d.rebnconv3.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage5d.rebnconv4.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))), ('stage5d.rebnconv3d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))), ('stage5d.rebnconv2d.conv_s1', Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage5d.rebnconv1d.conv_s1', Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconvin.conv_s1', Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv1.conv_s1', Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv2.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv3.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv4.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage4d.rebnconv3d.conv_s1', Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv2d.conv_s1', Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage4d.rebnconv1d.conv_s1', Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconvin.conv_s1', Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv1.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv2.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv3.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv4.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv5.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage3d.rebnconv4d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv3d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv2d.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage3d.rebnconv1d.conv_s1', Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconvin.conv_s1', Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv1.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv2.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv3.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv4.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv5.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv6.conv_s1', Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage2d.rebnconv5d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv4d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv3d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv2d.conv_s1', Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage2d.rebnconv1d.conv_s1', Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconvin.conv_s1', Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv1.conv_s1', Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv2.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv3.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv4.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv5.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv6.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv7.conv_s1', Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))), ('stage1d.rebnconv6d.conv_s1', Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv5d.conv_s1', Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv4d.conv_s1', Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv3d.conv_s1', Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv2d.conv_s1', Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('stage1d.rebnconv1d.conv_s1', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side1', Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side2', Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side3', Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side4', Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side5', Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))), ('side6', Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)))]\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Custom filtering rule\n",
        "def should_wrap(name):\n",
        "    return not any(skip in name for skip in [\".norm\", \".bn\", \"lora_\", \".bias\"])\n",
        "\n",
        "# Wrap selected Conv2d layers with LoRA\n",
        "layers_to_wrap = []\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Conv2d) and should_wrap(name):\n",
        "        layers_to_wrap.append((name, module))\n",
        "\n",
        "print(\"Layers to wrap:\", layers_to_wrap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QYwDk6GgaOE",
        "outputId": "33fa4ef5-16ac-460e-f436-b26632d329ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrapping:  conv_in\n",
            "Wrapping:  stage1.rebnconvin.conv_s1\n",
            "Wrapping:  stage1.rebnconv1.conv_s1\n",
            "Wrapping:  stage1.rebnconv2.conv_s1\n",
            "Wrapping:  stage1.rebnconv3.conv_s1\n",
            "Wrapping:  stage1.rebnconv4.conv_s1\n",
            "Wrapping:  stage1.rebnconv5.conv_s1\n",
            "Wrapping:  stage1.rebnconv6.conv_s1\n",
            "Wrapping:  stage1.rebnconv7.conv_s1\n",
            "Wrapping:  stage1.rebnconv6d.conv_s1\n",
            "Wrapping:  stage1.rebnconv5d.conv_s1\n",
            "Wrapping:  stage1.rebnconv4d.conv_s1\n",
            "Wrapping:  stage1.rebnconv3d.conv_s1\n",
            "Wrapping:  stage1.rebnconv2d.conv_s1\n",
            "Wrapping:  stage1.rebnconv1d.conv_s1\n",
            "Wrapping:  stage2.rebnconvin.conv_s1\n",
            "Wrapping:  stage2.rebnconv1.conv_s1\n",
            "Wrapping:  stage2.rebnconv2.conv_s1\n",
            "Wrapping:  stage2.rebnconv3.conv_s1\n",
            "Wrapping:  stage2.rebnconv4.conv_s1\n",
            "Wrapping:  stage2.rebnconv5.conv_s1\n",
            "Wrapping:  stage2.rebnconv6.conv_s1\n",
            "Wrapping:  stage2.rebnconv5d.conv_s1\n",
            "Wrapping:  stage2.rebnconv4d.conv_s1\n",
            "Wrapping:  stage2.rebnconv3d.conv_s1\n",
            "Wrapping:  stage2.rebnconv2d.conv_s1\n",
            "Wrapping:  stage2.rebnconv1d.conv_s1\n",
            "Wrapping:  stage3.rebnconvin.conv_s1\n",
            "Wrapping:  stage3.rebnconv1.conv_s1\n",
            "Wrapping:  stage3.rebnconv2.conv_s1\n",
            "Wrapping:  stage3.rebnconv3.conv_s1\n",
            "Wrapping:  stage3.rebnconv4.conv_s1\n",
            "Wrapping:  stage3.rebnconv5.conv_s1\n",
            "Wrapping:  stage3.rebnconv4d.conv_s1\n",
            "Wrapping:  stage3.rebnconv3d.conv_s1\n",
            "Wrapping:  stage3.rebnconv2d.conv_s1\n",
            "Wrapping:  stage3.rebnconv1d.conv_s1\n",
            "Wrapping:  stage4.rebnconvin.conv_s1\n",
            "Wrapping:  stage4.rebnconv1.conv_s1\n",
            "Wrapping:  stage4.rebnconv2.conv_s1\n",
            "Wrapping:  stage4.rebnconv3.conv_s1\n",
            "Wrapping:  stage4.rebnconv4.conv_s1\n",
            "Wrapping:  stage4.rebnconv3d.conv_s1\n",
            "Wrapping:  stage4.rebnconv2d.conv_s1\n",
            "Wrapping:  stage4.rebnconv1d.conv_s1\n",
            "Wrapping:  stage5.rebnconvin.conv_s1\n",
            "Wrapping:  stage5.rebnconv1.conv_s1\n",
            "Wrapping:  stage5.rebnconv2.conv_s1\n",
            "Wrapping:  stage5.rebnconv3.conv_s1\n",
            "Wrapping:  stage5.rebnconv4.conv_s1\n",
            "Wrapping:  stage5.rebnconv3d.conv_s1\n",
            "Wrapping:  stage5.rebnconv2d.conv_s1\n",
            "Wrapping:  stage5.rebnconv1d.conv_s1\n",
            "Wrapping:  stage6.rebnconvin.conv_s1\n",
            "Wrapping:  stage6.rebnconv1.conv_s1\n",
            "Wrapping:  stage6.rebnconv2.conv_s1\n",
            "Wrapping:  stage6.rebnconv3.conv_s1\n",
            "Wrapping:  stage6.rebnconv4.conv_s1\n",
            "Wrapping:  stage6.rebnconv3d.conv_s1\n",
            "Wrapping:  stage6.rebnconv2d.conv_s1\n",
            "Wrapping:  stage6.rebnconv1d.conv_s1\n",
            "Wrapping:  stage5d.rebnconvin.conv_s1\n",
            "Wrapping:  stage5d.rebnconv1.conv_s1\n",
            "Wrapping:  stage5d.rebnconv2.conv_s1\n",
            "Wrapping:  stage5d.rebnconv3.conv_s1\n",
            "Wrapping:  stage5d.rebnconv4.conv_s1\n",
            "Wrapping:  stage5d.rebnconv3d.conv_s1\n",
            "Wrapping:  stage5d.rebnconv2d.conv_s1\n",
            "Wrapping:  stage5d.rebnconv1d.conv_s1\n",
            "Wrapping:  stage4d.rebnconvin.conv_s1\n",
            "Wrapping:  stage4d.rebnconv1.conv_s1\n",
            "Wrapping:  stage4d.rebnconv2.conv_s1\n",
            "Wrapping:  stage4d.rebnconv3.conv_s1\n",
            "Wrapping:  stage4d.rebnconv4.conv_s1\n",
            "Wrapping:  stage4d.rebnconv3d.conv_s1\n",
            "Wrapping:  stage4d.rebnconv2d.conv_s1\n",
            "Wrapping:  stage4d.rebnconv1d.conv_s1\n",
            "Wrapping:  stage3d.rebnconvin.conv_s1\n",
            "Wrapping:  stage3d.rebnconv1.conv_s1\n",
            "Wrapping:  stage3d.rebnconv2.conv_s1\n",
            "Wrapping:  stage3d.rebnconv3.conv_s1\n",
            "Wrapping:  stage3d.rebnconv4.conv_s1\n",
            "Wrapping:  stage3d.rebnconv5.conv_s1\n",
            "Wrapping:  stage3d.rebnconv4d.conv_s1\n",
            "Wrapping:  stage3d.rebnconv3d.conv_s1\n",
            "Wrapping:  stage3d.rebnconv2d.conv_s1\n",
            "Wrapping:  stage3d.rebnconv1d.conv_s1\n",
            "Wrapping:  stage2d.rebnconvin.conv_s1\n",
            "Wrapping:  stage2d.rebnconv1.conv_s1\n",
            "Wrapping:  stage2d.rebnconv2.conv_s1\n",
            "Wrapping:  stage2d.rebnconv3.conv_s1\n",
            "Wrapping:  stage2d.rebnconv4.conv_s1\n",
            "Wrapping:  stage2d.rebnconv5.conv_s1\n",
            "Wrapping:  stage2d.rebnconv6.conv_s1\n",
            "Wrapping:  stage2d.rebnconv5d.conv_s1\n",
            "Wrapping:  stage2d.rebnconv4d.conv_s1\n",
            "Wrapping:  stage2d.rebnconv3d.conv_s1\n",
            "Wrapping:  stage2d.rebnconv2d.conv_s1\n",
            "Wrapping:  stage2d.rebnconv1d.conv_s1\n",
            "Wrapping:  stage1d.rebnconvin.conv_s1\n",
            "Wrapping:  stage1d.rebnconv1.conv_s1\n",
            "Wrapping:  stage1d.rebnconv2.conv_s1\n",
            "Wrapping:  stage1d.rebnconv3.conv_s1\n",
            "Wrapping:  stage1d.rebnconv4.conv_s1\n",
            "Wrapping:  stage1d.rebnconv5.conv_s1\n",
            "Wrapping:  stage1d.rebnconv6.conv_s1\n",
            "Wrapping:  stage1d.rebnconv7.conv_s1\n",
            "Wrapping:  stage1d.rebnconv6d.conv_s1\n",
            "Wrapping:  stage1d.rebnconv5d.conv_s1\n",
            "Wrapping:  stage1d.rebnconv4d.conv_s1\n",
            "Wrapping:  stage1d.rebnconv3d.conv_s1\n",
            "Wrapping:  stage1d.rebnconv2d.conv_s1\n",
            "Wrapping:  stage1d.rebnconv1d.conv_s1\n",
            "Wrapping:  side1\n",
            "Wrapping:  side2\n",
            "Wrapping:  side3\n",
            "Wrapping:  side4\n",
            "Wrapping:  side5\n",
            "Wrapping:  side6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BriaRMBG(\n",
              "  (conv_in): LoRAConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (lora_A): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (pool_in): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage1): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage2): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage3): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage4): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool45): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage5): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool56): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage6): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage5d): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage4d): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage3d): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage2d): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1d): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (side1): LoRAConv2d(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side2): LoRAConv2d(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side3): LoRAConv2d(\n",
              "    (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side4): LoRAConv2d(\n",
              "    (conv): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side5): LoRAConv2d(\n",
              "    (conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side6): LoRAConv2d(\n",
              "    (conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for name, module in layers_to_wrap:\n",
        "    print(\"Wrapping: \", name)\n",
        "    parts = name.split(\".\")\n",
        "    parent = model\n",
        "    for part in parts[:-1]:\n",
        "        parent = getattr(parent, part)\n",
        "    setattr(parent, parts[-1], LoRAConv2d(module, r=32, alpha=16))\n",
        "\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6ZnEjtCgeJR",
        "outputId": "2e45b808-5631-4c30-b653-82df8be24194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable: conv_in.lora_A.weight torch.Size([32, 3, 1, 1])\n",
            "Trainable: conv_in.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage1.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconvin.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv1.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv2.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv3.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv4.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv5.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv6.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv6.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv7.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv7.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv6d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv6d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv5d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv5d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv4d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv3d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv2d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1.rebnconv1d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage2.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconvin.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage2.rebnconv1.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv2.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv3.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv4.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv5.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv6.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv6.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv5d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconv5d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconv4d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconv3d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconv2d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2.rebnconv1d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage3.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3.rebnconvin.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage3.rebnconv1.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3.rebnconv2.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3.rebnconv3.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3.rebnconv4.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3.rebnconv5.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3.rebnconv4d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3.rebnconv3d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3.rebnconv2d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3.rebnconv1d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage4.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4.rebnconvin.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage4.rebnconv1.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4.rebnconv2.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4.rebnconv3.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4.rebnconv4.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4.rebnconv3d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4.rebnconv2d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4.rebnconv1d.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage5.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5.rebnconvin.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5.rebnconv1.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5.rebnconv2.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5.rebnconv3.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5.rebnconv4.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5.rebnconv3d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5.rebnconv2d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5.rebnconv1d.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage6.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage6.rebnconvin.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage6.rebnconv1.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage6.rebnconv2.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage6.rebnconv3.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage6.rebnconv4.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage6.rebnconv3d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage6.rebnconv2d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage6.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage6.rebnconv1d.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 1024, 1, 1])\n",
            "Trainable: stage5d.rebnconvin.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5d.rebnconv1.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5d.rebnconv2.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5d.rebnconv3.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage5d.rebnconv4.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5d.rebnconv3d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5d.rebnconv2d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage5d.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage5d.rebnconv1d.conv_s1.lora_B.weight torch.Size([512, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 1024, 1, 1])\n",
            "Trainable: stage4d.rebnconvin.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4d.rebnconv1.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4d.rebnconv2.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4d.rebnconv3.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage4d.rebnconv4.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4d.rebnconv3d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4d.rebnconv2d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage4d.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage4d.rebnconv1d.conv_s1.lora_B.weight torch.Size([256, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: stage3d.rebnconvin.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3d.rebnconv1.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3d.rebnconv2.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3d.rebnconv3.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3d.rebnconv4.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage3d.rebnconv5.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3d.rebnconv4d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3d.rebnconv3d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3d.rebnconv2d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage3d.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage3d.rebnconv1d.conv_s1.lora_B.weight torch.Size([128, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: stage2d.rebnconvin.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv1.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv2.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv3.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv4.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv5.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv6.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv6.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv5d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv5d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv4d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv3d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv2d.conv_s1.lora_B.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage2d.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage2d.rebnconv1d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconvin.conv_s1.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: stage1d.rebnconvin.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv1.conv_s1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: stage1d.rebnconv1.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv2.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv2.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv3.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv3.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv4.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv4.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv5.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv5.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv6.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv6.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv7.conv_s1.lora_A.weight torch.Size([32, 16, 1, 1])\n",
            "Trainable: stage1d.rebnconv7.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv6d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv6d.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv5d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv5d.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv4d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv4d.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv3d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv3d.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv2d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv2d.conv_s1.lora_B.weight torch.Size([16, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv1d.conv_s1.lora_A.weight torch.Size([32, 32, 1, 1])\n",
            "Trainable: stage1d.rebnconv1d.conv_s1.lora_B.weight torch.Size([64, 32, 1, 1])\n",
            "Trainable: side1.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: side1.lora_B.weight torch.Size([1, 32, 1, 1])\n",
            "Trainable: side2.lora_A.weight torch.Size([32, 64, 1, 1])\n",
            "Trainable: side2.lora_B.weight torch.Size([1, 32, 1, 1])\n",
            "Trainable: side3.lora_A.weight torch.Size([32, 128, 1, 1])\n",
            "Trainable: side3.lora_B.weight torch.Size([1, 32, 1, 1])\n",
            "Trainable: side4.lora_A.weight torch.Size([32, 256, 1, 1])\n",
            "Trainable: side4.lora_B.weight torch.Size([1, 32, 1, 1])\n",
            "Trainable: side5.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: side5.lora_B.weight torch.Size([1, 32, 1, 1])\n",
            "Trainable: side6.lora_A.weight torch.Size([32, 512, 1, 1])\n",
            "Trainable: side6.lora_B.weight torch.Size([1, 32, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(\"Trainable:\", name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSmkLoMjgeAK",
        "outputId": "0a46ba52-85d9-451d-eee7-b762916e225e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable params: 1154336 / 45201126 (2.55%)\n"
          ]
        }
      ],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Trainable params: {trainable} / {total} ({100 * trainable / total:.2f}%)\")\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvLk465bgd4X"
      },
      "outputs": [],
      "source": [
        "lora_params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(lora_params, lr=1e-4)\n",
        "loss_fn = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VauzSKegdw5"
      },
      "outputs": [],
      "source": [
        "dataset = RMBGDataset(df)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQKfVGfLglo_",
        "outputId": "617c0024-0357-4591-86db-a308952522a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BriaRMBG(\n",
              "  (conv_in): LoRAConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (lora_A): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (pool_in): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage1): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage2): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage3): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage4): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool45): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage5): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pool56): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (stage6): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage5d): RSU4F(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage4d): RSU4(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage3d): RSU5(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage2d): RSU6(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (stage1d): RSU7(\n",
              "    (rebnconvin): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv2): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv3): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv4): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv5): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (rebnconv6): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv7): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "        (lora_A): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv6d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv5d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv4d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv3d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv2d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "    (rebnconv1d): REBNCONV(\n",
              "      (conv_s1): LoRAConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (lora_A): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (lora_B): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (bn_s1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu_s1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (side1): LoRAConv2d(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side2): LoRAConv2d(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side3): LoRAConv2d(\n",
              "    (conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side4): LoRAConv2d(\n",
              "    (conv): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side5): LoRAConv2d(\n",
              "    (conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              "  (side6): LoRAConv2d(\n",
              "    (conv): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (lora_A): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (lora_B): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI48w2_tTqNR",
        "outputId": "5012c291-78c8-4cb2-fa87-a470c7495522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30] __ Loss: 0.2320 __ Accuracy: 69.76% __ IoU: 0.6003 __ Time: 52.47 sec\n",
            "Epoch [2/30] __ Loss: 0.2225 __ Accuracy: 69.62% __ IoU: 0.5972 __ Time: 51.87 sec\n",
            "Epoch [3/30] __ Loss: 0.1888 __ Accuracy: 69.82% __ IoU: 0.6048 __ Time: 52.24 sec\n",
            "Epoch [4/30] __ Loss: 0.1672 __ Accuracy: 69.93% __ IoU: 0.6098 __ Time: 51.96 sec\n",
            "Epoch [5/30] __ Loss: 0.1924 __ Accuracy: 69.91% __ IoU: 0.6069 __ Time: 52.02 sec\n",
            "Epoch [6/30] __ Loss: 0.1690 __ Accuracy: 69.84% __ IoU: 0.6104 __ Time: 52.08 sec\n",
            "Epoch [7/30] __ Loss: 0.1572 __ Accuracy: 69.90% __ IoU: 0.6125 __ Time: 51.96 sec\n",
            "Epoch [8/30] __ Loss: 0.1613 __ Accuracy: 69.72% __ IoU: 0.6152 __ Time: 52.08 sec\n",
            "Epoch [9/30] __ Loss: 0.1639 __ Accuracy: 69.99% __ IoU: 0.6139 __ Time: 52.03 sec\n",
            "Epoch [10/30] __ Loss: 0.1473 __ Accuracy: 70.02% __ IoU: 0.6190 __ Time: 51.91 sec\n",
            "Epoch [11/30] __ Loss: 0.1350 __ Accuracy: 70.07% __ IoU: 0.6192 __ Time: 52.08 sec\n",
            "Epoch [12/30] __ Loss: 0.1331 __ Accuracy: 69.99% __ IoU: 0.6206 __ Time: 51.97 sec\n",
            "Epoch [13/30] __ Loss: 0.1311 __ Accuracy: 70.07% __ IoU: 0.6202 __ Time: 51.97 sec\n",
            "Epoch [14/30] __ Loss: 0.1335 __ Accuracy: 70.06% __ IoU: 0.6217 __ Time: 52.00 sec\n",
            "Epoch [15/30] __ Loss: 0.1824 __ Accuracy: 69.87% __ IoU: 0.6208 __ Time: 51.91 sec\n",
            "Epoch [16/30] __ Loss: 0.1295 __ Accuracy: 70.10% __ IoU: 0.6211 __ Time: 52.05 sec\n",
            "Epoch [17/30] __ Loss: 0.1213 __ Accuracy: 70.18% __ IoU: 0.6227 __ Time: 52.01 sec\n",
            "Epoch [18/30] __ Loss: 0.1452 __ Accuracy: 70.03% __ IoU: 0.6234 __ Time: 51.91 sec\n",
            "Epoch [19/30] __ Loss: 0.1345 __ Accuracy: 70.05% __ IoU: 0.6226 __ Time: 52.08 sec\n",
            "Epoch [20/30] __ Loss: 0.1166 __ Accuracy: 70.27% __ IoU: 0.6231 __ Time: 51.80 sec\n",
            "Epoch [21/30] __ Loss: 0.1207 __ Accuracy: 70.19% __ IoU: 0.6236 __ Time: 51.94 sec\n",
            "Epoch [22/30] __ Loss: 0.1144 __ Accuracy: 70.27% __ IoU: 0.6256 __ Time: 52.09 sec\n",
            "Epoch [23/30] __ Loss: 0.1128 __ Accuracy: 70.26% __ IoU: 0.6245 __ Time: 51.93 sec\n",
            "Epoch [24/30] __ Loss: 0.1144 __ Accuracy: 70.29% __ IoU: 0.6250 __ Time: 51.89 sec\n",
            "Epoch [25/30] __ Loss: 0.1201 __ Accuracy: 70.32% __ IoU: 0.6238 __ Time: 51.99 sec\n",
            "Epoch [26/30] __ Loss: 0.1231 __ Accuracy: 70.22% __ IoU: 0.6256 __ Time: 51.95 sec\n",
            "Epoch [27/30] __ Loss: 0.1114 __ Accuracy: 70.28% __ IoU: 0.6261 __ Time: 51.94 sec\n",
            "Epoch [28/30] __ Loss: 0.1197 __ Accuracy: 70.22% __ IoU: 0.6262 __ Time: 51.99 sec\n",
            "Epoch [29/30] __ Loss: 0.1080 __ Accuracy: 70.31% __ IoU: 0.6267 __ Time: 51.93 sec\n",
            "Epoch [30/30] __ Loss: 0.1063 __ Accuracy: 70.27% __ IoU: 0.6274 __ Time: 52.07 sec\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "accuracies = []\n",
        "ious = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    total_pixels = 0\n",
        "    correct_pixels = 0\n",
        "    total_iou = 0.0\n",
        "    total_batches = 0\n",
        "    total_time = 0.0\n",
        "\n",
        "    start_time = time.perf_counter()\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        images = batch[\"pixel_values\"].to(device)\n",
        "        masks = batch[\"mask\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(images)[0][5]\n",
        "\n",
        "        if preds.shape != masks.shape:\n",
        "            preds = preds.squeeze(1)\n",
        "\n",
        "        loss = loss_fn(preds, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_batches += 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predicted_mask = (preds > 0.5).float()\n",
        "\n",
        "            correct_pixels += (predicted_mask == masks).sum().item()\n",
        "            total_pixels += masks.numel()\n",
        "\n",
        "            intersection = (predicted_mask * masks).sum(dim=(1, 2))\n",
        "            union = predicted_mask.sum(dim=(1, 2)) + masks.sum(dim=(1, 2)) - intersection + 1e-6\n",
        "            batch_iou = (intersection / union).mean().item()\n",
        "            total_iou += batch_iou\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "    accuracy = 100 * correct_pixels / total_pixels\n",
        "    avg_iou = total_iou / total_batches\n",
        "\n",
        "    losses.append(avg_loss)\n",
        "    accuracies.append(accuracy)\n",
        "    ious.append(avg_iou)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] __ Loss: {avg_loss:.4f} __ Accuracy: {accuracy:.2f}% __ IoU: {avg_iou:.4f} __ Time: {total_time:.2f} sec\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc-N8A-xchqu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "09d00f2e-5f5f-48bb-c107-5951413a635c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(epochs, losses, label='Loss', color='red')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, accuracies, label='Pixel Accuracy (%)', color='blue')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Pixel Accuracy over Epochs')\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot IoU\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(epochs, ious, label='IoU', color='green')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU')\n",
        "plt.title('IoU over Epochs')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3cYqu42cvlA"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"rmbg-finetuned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDHxDtImcwfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad260871-dd56-445e-a17d-71c9fbe5cc11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RepoUrl('https://huggingface.co/ahmedtarfa/rmbg-1.4-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='ahmedtarfa/rmbg-1.4-finetuned')"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "create_repo(\"rmbg-1.4-finetuned\", private=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_E28go3czja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "cc809d91186d4f48a4e45cd94d0ddac7",
            "4dbfb9c67d8c443587a2522fd953a9e4",
            "80c2d9d765b94a09a5c4355783a3499b",
            "15a5549c4dc74ca29a5c3d5ea90461a0",
            "2899f7fd41f640a281c5a0356dab032d",
            "d6f9abd958fe4156b89324fe41d2c517",
            "366199c5f09544328657151779e40a04",
            "66403b69b55a4244b8e02926f0386f6a",
            "75504ff9d68e4998948285041b2b6a11",
            "8ebee74ae5b14c0fa14355eaec65b929",
            "93a86de01c0440eabd5a91b2bee37a46"
          ]
        },
        "outputId": "3d0983cd-3adb-4ae2-e842-6ceb4bee6664"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/181M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc809d91186d4f48a4e45cd94d0ddac7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/ahmedtarfa/rmbg-1.4-finetuned/commit/9134eda9b05daca48b41c138bd4205dff6f1f416', commit_message='Upload fine-tuned RMBG model', commit_description='', oid='9134eda9b05daca48b41c138bd4205dff6f1f416', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ahmedtarfa/rmbg-1.4-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='ahmedtarfa/rmbg-1.4-finetuned'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "upload_folder(\n",
        "    folder_path=\"rmbg-finetuned\",\n",
        "    path_in_repo=\".\",  # root of the repo\n",
        "    repo_id=\"ahmedtarfa/rmbg-1.4-finetuned\",\n",
        "    repo_type=\"model\",\n",
        "    commit_message=\"Upload fine-tuned RMBG model\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  }
}